{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd9a2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "import torchaudio.transforms as T\n",
    "from transformers import ClapProcessor, ClapModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca3ca5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # CLAP-Compatible Text Descriptions for Each Tag\n",
    "# text_descriptions = {\n",
    "#     \"Soothing\": \"A gentle, calming song that helps soothe and regulate emotional states.\",\n",
    "#     \"Stimulating\": \"A vibrant and upbeat track designed to increase alertness and sensory engagement.\",\n",
    "#     \"Grounding\": \"A slow, repetitive melody that provides structure and emotional grounding.\",\n",
    "#     \"Playful\": \"An engaging and whimsical tune that encourages joy and playful interaction.\",\n",
    "#     \"Focusing\": \"A structured and predictable melody that helps children sustain attention and reduce distractions.\",\n",
    "#     \"Transitional\": \"A motivating and rhythmically clear piece used to support transitions between activities.\",\n",
    "#     \"Interactive\": \"A musical piece designed to invite turn-taking, imitation, and social play.\",\n",
    "#     \"Motivating\": \"A cheerful and energizing melody that inspires movement and participation.\",\n",
    "#     \"Anxiety-Reducing\": \"A soft and flowing piece that helps reduce sensory overload and anxiety.\",\n",
    "#     \"Task-Oriented\": \"A functional and directive tune used to support task initiation or completion.\",\n",
    "#     \"Self-Expressive\": \"A flexible, emotionally rich song that allows for personal vocal or instrumental expression.\",\n",
    "#     \"Sensory-Calming\": \"A low-frequency, mellow soundscape that promotes sensory regulation and relaxation.\",\n",
    "#     \"Attention-Shifting\": \"A contrasting and dynamic melody designed to redirect or refocus attention in therapeutic settings.\",\n",
    "#     \"Rhythmic Synchronizing\": \"A rhythmically steady piece that supports motor coordination and entrainment.\",\n",
    "#     \"Confidence-Building\": \"A triumphant and empowering melody that encourages self-esteem and initiative.\"\n",
    "# }\n",
    "\n",
    "# text_descriptions = {\n",
    "#     \"Soothing\": \"A gentle melodic layer with soft pad harmonies and flowing water sounds, promoting calm and relaxation.\",\n",
    "#     \"Stimulating\": \"An energetic musical track featuring rhythmic percussion, sharp bass, and dynamic tempo changes to engage movement.\",\n",
    "#     \"Grounding\": \"A steady rhythmic base and repetitive chord structure that helps stabilize emotional and sensory responses.\",\n",
    "#     \"Playful\": \"A whimsical tune with plucked strings, bell-like melodies, and light percussive textures that encourage joyful interaction.\",\n",
    "#     \"Focusing\": \"A repetitive harp or flute melody with consistent timing and predictable structure, aiding concentration and focus.\",\n",
    "#     \"Transitional\": \"A musically clear phrase with firm bass drum and synthesized rhythm, guiding activity shifts or transitions.\",\n",
    "#     \"Interactive\": \"A multi-layered song with call-and-response melodies and spacious textures for turn-taking and social engagement.\",\n",
    "#     \"Motivating\": \"An upbeat electric guitar and lead synth combination with medium tempo percussion to inspire active participation.\",\n",
    "#     \"Anxiety-Reducing\": \"A warm, slow-paced track using soft pads, descending melodic lines, and ambient textures to lower anxiety.\",\n",
    "#     \"Task-Oriented\": \"A track with consistent rhythmic pulses and directive harmonic cues that support initiation of structured activities.\",\n",
    "#     \"Self-Expressive\": \"An emotionally flexible piece featuring layered melodies and rich harmonies to support vocal or instrumental expression.\",\n",
    "#     \"Sensory-Calming\": \"A soft ambient mix of flowing water, sustained strings, and low-register harmony to reduce sensory overload.\",\n",
    "#     \"Attention-Shifting\": \"A contrasting track with register changes and sudden timbral shifts used to redirect attention gently.\",\n",
    "#     \"Rhythmic Synchronizing\": \"A repetitive percussive beat and walking bass line designed to promote motor coordination and entrainment.\",\n",
    "#     \"Confidence-Building\": \"A strong, uplifting melody with plucked bass and vibrant harmony that supports self-esteem and initiation.\"\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a352a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Functional Emotion Tags\n",
    "emotional_tags = [\n",
    "    \"Stimulating\", # High Arousal and High Valence\n",
    "    \"Playful\", # High Arousal and High Valence \n",
    "    \"Soothing\", # Low Arousal and High Valence\n",
    "    \"Sensory-Calming\", # Low Arousal and High Valence\n",
    "    \"Grounding\", # Low Arousal and Low Valence\n",
    "    \"Focusing\", # Low Arousal and Low Valence\n",
    "    \"Transitional\", # High Arousal and Low Valence\n",
    "    \"Anxiety-Reduction\" # High Arousal and Low Valence\n",
    "\n",
    "]\n",
    "\n",
    "text_descriptions = {\n",
    "    \"Stimulating\": \"A lively, energetic track with strong rhythm and upbeat tempo to boost movement and attention.\",\n",
    "    \"Playful\": \"A whimsical, bouncy track with light percussion and bright tones to encourage joyful exploration.\",\n",
    "    \"Soothing\": \"A calm, gentle track with soft melodies and slow tempo for relaxation and emotional regulation.\",\n",
    "    \"Sensory-Calming\": \"A track with ambient textures and minimal melodic content designed to reduce sensory overload.\",\n",
    "    \"Grounding\": \"A steady, repetitive musical base that promotes sensory stability and emotional anchoring.\",\n",
    "    \"Focusing\": \"A structured, predictable track with consistent rhythm to support sustained attention and task engagement.\",\n",
    "    \"Transitional\": \"A cue-based musical track used to signal transitions between activities or routines.\",\n",
    "    \"Anxiety-Reduction\": \"A soft, harmonically stable track specifically designed to ease agitation or anxious behaviors.\"\n",
    "}\n",
    "\n",
    "clap_model = ClapModel.from_pretrained(\"laion/clap-htsat-unfused\").to(device)\n",
    "clap_processor = ClapProcessor.from_pretrained(\"laion/clap-htsat-unfused\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff3e142",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audio(path, sr=48000):\n",
    "    waveform, original_sr = torchaudio.load(path)\n",
    "    if original_sr != sr:\n",
    "        waveform = T.Resample(orig_freq=original_sr, new_freq=sr)(waveform)\n",
    "    return waveform.mean(0).unsqueeze(0)\n",
    "\n",
    "def segment_audio(waveform, sr=48000, segment_sec=10, overlap_sec=5):\n",
    "    segment_len = segment_sec * sr\n",
    "    step = segment_len - overlap_sec * sr\n",
    "    return [waveform[:, i:i+segment_len] for i in range(0, waveform.size(1) - segment_len + 1, step)]\n",
    "\n",
    "def get_clap_audio_embedding(segments):\n",
    "    with torch.no_grad():\n",
    "        audio_embeds = []\n",
    "        for seg in segments:\n",
    "            inputs = clap_processor(audios=seg.squeeze(0), return_tensors=\"pt\", sampling_rate=48000).to(device)\n",
    "            embed = clap_model.get_audio_features(**inputs)\n",
    "            audio_embeds.append(embed)\n",
    "        return torch.mean(torch.stack(audio_embeds), dim=0)\n",
    "\n",
    "def get_clap_text_embeddings():\n",
    "    inputs = clap_processor(text=list(text_descriptions.values()), return_tensors=\"pt\", padding=True).to(device)\n",
    "    with torch.no_grad():\n",
    "        return clap_model.get_text_features(**inputs)\n",
    "\n",
    "def cosine_similarity_matrix(audio_embeds, text_embeds):\n",
    "    return F.cosine_similarity(audio_embeds.unsqueeze(1), text_embeds.unsqueeze(0), dim=2).cpu().numpy()\n",
    "\n",
    "def run_clap_audio_text_retrieval(input_folder, out_folder):\n",
    "    os.makedirs(out_folder, exist_ok=True)\n",
    "\n",
    "    audio_files = []\n",
    "    audio_embeddings = []\n",
    "\n",
    "    for root, _, files in os.walk(input_folder):\n",
    "        for file in files:\n",
    "            if not file.endswith(\".wav\"):\n",
    "                continue\n",
    "            try:\n",
    "                path = os.path.join(root, file)\n",
    "                print(f\"Processing: {path}\")\n",
    "                waveform = load_audio(path)\n",
    "                segments = segment_audio(waveform)\n",
    "                audio_embed = get_clap_audio_embedding(segments)\n",
    "                audio_embeddings.append(audio_embed.cpu())\n",
    "                audio_files.append(os.path.relpath(path, input_folder))\n",
    "            except Exception as e:\n",
    "                print(f\"Failed: {file} â€” {e}\")\n",
    "\n",
    "    audio_embeddings = torch.stack(audio_embeddings).squeeze(1).to(device)\n",
    "    text_embeddings = get_clap_text_embeddings()\n",
    "\n",
    "    sim_matrix = cosine_similarity_matrix(audio_embeddings, text_embeddings)\n",
    "\n",
    "    df_audio_to_text = pd.DataFrame(sim_matrix, columns=emotional_tags)\n",
    "    df_audio_to_text.insert(0, \"file_name\", audio_files)\n",
    "    df_audio_to_text.to_csv(os.path.join(out_folder, \"audio_to_text_similarity_refined.csv\"), index=False)\n",
    "\n",
    "    df_text_to_audio = pd.DataFrame(sim_matrix.T, index=emotional_tags, columns=audio_files).T\n",
    "    df_text_to_audio.to_csv(os.path.join(out_folder, \"text_to_audio_similarity_refined.csv\"))\n",
    "\n",
    "    print(\"Retrieval results saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4191f30f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run\n",
    "if __name__ == \"__main__\":\n",
    "    run_clap_audio_text_retrieval(\n",
    "        input_folder=\"<<Path to audio files>>\",\n",
    "        out_folder=\"<<Path to save the csvs>>\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8eac7c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
